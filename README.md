# Awesome Distribution/Property Inference in Machine Learning  [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
This repository contains a curated list of papers related to distribution inference/property inference in machine learning. A code repository is provided when available by the authors. For corrections, suggestions, or missing papers, please either open an issue or submit a pull request.

# Contents
- [Surveys and SoKs](#surveys-and-overviews)
- [Passive](#passive)
- [Poisoning](#poisoning)
- [User Level](#user-level)
- [Theory](#theory)
- [Auditing](#auditing)
- [Others](#others)

# Surveys and Overviews
- [SoK: Let The Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning](https://ieeexplore.ieee.org/abstract/document/10179281). Ahmed Salem, Giovanni Cherubin, David Evans, Boris Köpf, Andrew Paverd, Anshuman Suri, Shruti Tople, Santiago Zanella-Béguelin. IEEE S&P, 2023.

# Passive
- [Hacking Smart Machines with Smarter Ones: How to Extract Meaningful Data from Machine Learning Classifiers](https://www.inderscienceonline.com/doi/abs/10.1504/IJSN.2015.071829). Giuseppe Ateniese, Luigi V. Mancini, Angelo Spognardi, Antonio Villani, Domenico Vitali and Giovanni Felici. International Journal of Security and Networks, 2015.
- [Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations](https://dl.acm.org/doi/abs/10.1145/3243734.3243834). Karan Ganju, Qi Wang, Wei Yang, Carl A. Gunter, Nikita Borisov. CCS, 2018.
- [Formalizing and Estimating Distribution Inference Risks](https://petsymposium.org/2022/files/papers/issue4/popets-2022-0121.pdf). Anshuman Suri and David Evans. PETS, 2022. ([code](https://github.com/iamgroot42/FormEstDistRisks))
- [Dissecting Distribution Inference](https://ieeexplore.ieee.org/abstract/document/10136142). Anshuman Suri, Yifu Lu, Yanjin Chen, David Evans. IEEE SaTML, 2023. ([code](https://github.com/iamgroot42/dissecting_dist_inf))
- [Leakage of Dataset Properties in Multi-Party Machine Learning](https://www.usenix.org/system/files/sec21-zhang-wanrong.pdf). Wanrong Zhang, Shruti Tople, Olga Ohrimenko. USENIX Security 2021.
- [Correlation Inference Attacks against Machine Learning Models](https://arxiv.org/abs/2112.08806). Ana-Maria Cretu*, Florent Guepin*, and Yves-Alexandre de Montjoye. arxiv, 2021. 

# Poisoning
- [Property Inference from Poisoning](https://ieeexplore.ieee.org/abstract/document/9833623). Saeed Mahloujifar, Esha Ghosh, Melissa Chase. IEEE S&P, 2022.
- [SNAP: Efficient Extraction of Private Properties with Poisoning](https://ieeexplore.ieee.org/abstract/document/10179334). Harsh Chaudhari, John Abascal, Alina Oprea, Matthew Jagielski, Florian Tramèr, Jonathan Ullman. IEEE SaTML, 2023. ([code](https://github.com/johnmath/snap-sp23))
- [Manipulating Transfer Learning for Property Inference](https://openaccess.thecvf.com/content/CVPR2023/html/Tian_Manipulating_Transfer_Learning_for_Property_Inference_CVPR_2023_paper.html). Yulong Tian, Fnu Suya, Anshuman Suri, Fengyuan Xu, David Evans. CVPR, 2023. ([code](https://github.com/yulongt23/Transfer-Inference))

# User Level

- [Subject Membership Inference Attacks in Federated Learning](https://arxiv.org/abs/2206.03317). Anshuman Suri, Pallika Kanani, Virendra J. Marathe, Daniel W. Peterson. arXiv, 2022. 
- [User Inference Attacks on Large Language Models](https://arxiv.org/abs/2310.09266). Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, Zheng Xu. arXiv, 2023.
- [FACE-AUDITOR: Data Auditing in Facial Recognition Systems](https://www.usenix.org/conference/usenixsecurity23/presentation/chen-min). Min Chen, Zhikun Zhang, Tianhao Wang, Michael Backes, Yang Zhang. USENIX, 2023. ([code](https://github.com/minChen00/Face-Auditor/))
- [User-Level Membership Inference Attack against Metric Embedding Learning](https://arxiv.org/abs/2203.02077). Guoyao Li, Shahbaz Rezaei, Xin Liu. ICLR PAIR^2Struct Workshop, 2022.
- [Inference Attacks Against Face Recognition Model without Classification Layers](https://arxiv.org/abs/2401.13719). Yuanqing Huang, Huilong Chen, Yinggui Wang, Lei Wang. arXiv, 2024.
- [SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker Recognition Systems](https://arxiv.org/abs/2309.07983). Guangke Chen, Yedi Zhang, Fu Song. arXiv, 2023.

# Theory
- [Formalizing and Estimating Distribution Inference Risks](https://petsymposium.org/2022/files/papers/issue4/popets-2022-0121.pdf). Anshuman Suri and David Evans. PETS, 2022. ([code](https://github.com/iamgroot42/FormEstDistRisks))
- [Protecting Global Properties of Datasets with Distribution Privacy Mechanisms](https://proceedings.mlr.press/v206/chen23f.html). Michelle Chen and Olga Ohrimenko. AISTATS, 2023. ([code](https://github.com/mgcsls/mechanisms-global-properties))
- [Distribution inference risks: Identifying and mitigating sources of leakage](https://ieeexplore.ieee.org/abstract/document/10136150). Valentin Hartmann, Léo Meynent, Maxime Peyrard, Dimitrios Dimitriadis, Shruti Tople, Robert West. IEEE SaTML, 2023. ([code](https://github.com/epfl-dlab/distribution-inference-risks))

# Auditing
- [Black-Box Audits for Group Distribution Shifts](https://arxiv.org/abs/2209.03620). Marc Juarez, Samuel Yeom, Matt Fredrikson. arXiv, 2022. 
- [Attesting Distributional Properties of Training Data for Machine Learning](https://arxiv.org/abs/2308.09552). Vasisht Duddu, Anudeep Das, Nora Khayata, Hossein Yalame, Thomas Schneider, N. Asokan. arXiv, 2023. 

# Others
